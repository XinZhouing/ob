## 统计时间增长趋势

时间复杂度分析统计的不是算法运行时间，**而是算法运行时间随着数据量变大时的增长趋势**。

“时间增长趋势”这个概念比较抽象，我们通过一个例子来加以理解。假设输入数据大小为 𝑛 ，给定三个算法 `A`、`B` 和 `C` ：
```java
// 算法 A 的时间复杂度：常数阶
void algorithm_A(int n) {
    System.out.println(0);
}
// 算法 B 的时间复杂度：线性阶
void algorithm_B(int n) {
    for (int i = 0; i < n; i++) {
        System.out.println(0);
    }
}
// 算法 C 的时间复杂度：常数阶
void algorithm_C(int n) {
    for (int i = 0; i < 1000000; i++) {
        System.out.println(0);
    }
}
```
![[Pasted image 20240517231949.png]]
相较于直接统计算法的运行时间，时间复杂度分析有哪些特点呢？

- **时间复杂度能够有效评估算法效率**。例如，算法 `B` 的运行时间呈线性增长，在 𝑛>1 时比算法 `A` 更慢，在 𝑛>1000000 时比算法 `C` 更慢。事实上，只要输入数据大小 𝑛 足够大，复杂度为“常数阶”的算法一定优于“线性阶”的算法，这正是时间增长趋势的含义。
- **时间复杂度的推算方法更简便**。显然，运行平台和计算操作类型都与算法运行时间的增长趋势无关。因此在时间复杂度分析中，我们可以简单地将所有计算操作的执行时间视为相同的“单位时间”，从而将“计算操作运行时间统计”简化为“计算操作数量统计”，这样一来估算难度就大大降低了。
- **时间复杂度也存在一定的局限性**。例如，尽管算法 `A` 和 `C` 的时间复杂度相同，但实际运行时间差别很大。同样，尽管算法 `B` 的时间复杂度比 `C` 高，但在输入数据大小 𝑛 较小时，算法 `B` 明显优于算法 `C` 。在这些情况下，我们很难仅凭时间复杂度判断算法效率的高低。当然，尽管存在上述问题，复杂度分析仍然是评判算法效率最有效且常用的方法。
## 函数渐近上界

给定一个输入大小为 𝑛 的函数：
```java
void algorithm(int n) {
    int a = 1;  // +1
    a = a + 1;  // +1
    a = a * 2;  // +1
    // 循环 n 次
    for (int i = 0; i < n; i++) { // +1（每轮都执行 i ++）
        System.out.println(0);    // +1
    }
}
```
设算法的操作数量是一个关于输入数据大小 𝑛 的函数，记为 𝑇(𝑛) ，则以上函数的操作数量为：

<center>𝑇(𝑛)=3+2𝑛</center>

𝑇(𝑛) 是一次函数，说明其运行时间的增长趋势是线性的，因此它的时间复杂度是线性阶。

我们将线性阶的时间复杂度记为 𝑂(𝑛) ，这个数学符号称为<u>大 𝑂 记号（big-𝑂 notation</u>），表示函数 𝑇(𝑛) 的<u>渐近上界（asymptotic upper bound）。
</u>
时间复杂度分析本质上是计算“操作数量 𝑇(𝑛)”的渐近上界，它具有明确的数学定义。

> [!NOTE] 函数渐近上界
> 若存在正实数 𝑐 和实数 𝑛0 ，使得对于所有的 𝑛>𝑛0 ，均有 𝑇(𝑛)≤𝑐⋅𝑓(𝑛) ，则可认为 𝑓(𝑛) 给出了 𝑇(𝑛) 的一个渐近上界，记为 𝑇(𝑛)=𝑂(𝑓(𝑛)) 。

如图所示，计算渐近上界就是寻找一个函数 𝑓(𝑛) ，使得当 𝑛 趋向于无穷大时，𝑇(𝑛) 和 𝑓(𝑛) 处于相同的增长级别，仅相差一个常数项 𝑐 的倍数。
![[Pasted image 20240517232715.png]]
## 推算方法

根据定义，确定 𝑓(𝑛) 之后，我们便可得到时间复杂度 𝑂(𝑓(𝑛)) 。那么如何确定渐近上界 𝑓(𝑛) 呢？总体分为两步：首先统计操作数量，然后判断渐近上界。
### 1.   第一步：统计操作数量

针对代码，逐行从上到下计算即可。然而，由于上述 𝑐⋅𝑓(𝑛) 中的常数项 𝑐 可以取任意大小，**因此操作数量 𝑇(𝑛) 中的各种系数、常数项都可以忽略**。根据此原则，可以总结出以下计数简化技巧。

1. **忽略 𝑇(𝑛) 中的常数项**。因为它们都与 𝑛 无关，所以对时间复杂度不产生影响。
2. **省略所有系数**。例如，循环 2𝑛 次、5𝑛+1 次等，都可以简化记为 𝑛 次，因为 𝑛 前面的系数对时间复杂度没有影响。
3. **循环嵌套时使用乘法**。总操作数量等于外层循环和内层循环操作数量之积，每一层循环依然可以分别套用第 `1.` 点和第 `2.` 点的技巧。

给定一个函数，我们可以用上述技巧来统计操作数量：
```java
void algorithm(int n) {
    int a = 1;  // +0（技巧 1）
    a = a + n;  // +0（技巧 1）
    // +n（技巧 2）
    for (int i = 0; i < 5 * n + 1; i++) {
        System.out.println(0);
    }
    // +n*n（技巧 3）
    for (int i = 0; i < 2 * n; i++) {
        for (int j = 0; j < n + 1; j++) {
            System.out.println(0);
        }
    }
}
```
以下公式展示了使用上述技巧前后的统计结果，两者推算出的时间复杂度都为 𝑂(𝑛<sup>2</sup>) 。

𝑇(𝑛)=2𝑛(𝑛+1)+(5𝑛+1)+2完整统计
	=2𝑛<sup>2</sup>+7𝑛+3
𝑇(𝑛)=𝑛<sup>2</sup>+𝑛偷懒统计 (o.O)

### 2.   第二步：判断渐近上界
**时间复杂度由 𝑇(𝑛) 中最高阶的项来决定**。这是因为在 𝑛 趋于无穷大时，最高阶的项将发挥主导作用，其他项的影响都可以忽略。

下表展示了不同操作数量对应的时间复杂度，其中一些夸张的值是为了强调“系数无法撼动阶数”这一结论。当 𝑛 趋于无穷大时，这些常数变得无足轻重。

| 操作数量 𝑇(𝑛)                        | 时间复杂度 𝑂(𝑓(𝑛))   |
| ---------------------------------- | ------------------ |
| 100000                             | 𝑂(1)              |
| 3𝑛+2                              | 𝑂(𝑛)             |
| 2𝑛<sup>2</sup>+3𝑛+2              | 𝑂(𝑛<sup>2</sup>) |
| 𝑛<sup>3</sup>+10000𝑛<sup>2</sup> | 𝑂(𝑛<sup>3</sup>) |
| 2𝑛+10000𝑛<sup>10000</sup>        | 𝑂(2𝑛)            |

## 常见类型

设输入数据大小为 𝑛 ，常见的时间复杂度类型如图 2-9 所示（按照从低到高的顺序排列）。
$$
𝑂(1)<𝑂(log⁡𝑛)<𝑂(𝑛)<𝑂(𝑛log⁡𝑛)<𝑂(𝑛2)<𝑂(2𝑛)<𝑂(𝑛!)
$$
$$
常数阶<对数阶<线性阶<线性对数阶<平方阶<指数阶<阶乘阶
$$
![[Pasted image 20240524135143.png]]
### 1.   常数阶 𝑂(1)

常数阶的操作数量与输入数据大小 𝑛 无关，即不随着 𝑛 的变化而变化。

在以下函数中，尽管操作数量 `size` 可能很大，但由于其与输入数据大小 𝑛 无关，因此时间复杂度仍为 𝑂(1) ：
```java
/* 常数阶 */
int constant(int n) {
    int count = 0;
    int size = 100000;
    for (int i = 0; i < size; i++)
        count++;
    return count;
}
```
### 2.   线性阶 𝑂(𝑛)

线性阶的操作数量相对于输入数据大小 𝑛 以线性级别增长。线性阶通常出现在单层循环中：
```java
/* 线性阶 */
int linear(int n) {
    int count = 0;
    for (int i = 0; i < n; i++)
        count++;
    return count;
}
```
### 3.   平方阶 𝑂(𝑛<sup>2</sup>)

平方阶的操作数量相对于输入数据大小 𝑛 以平方级别增长。平方阶通常出现在嵌套循环中，外层循环和内层循环的时间复杂度都为 𝑂(𝑛) ，因此总体的时间复杂度为 𝑂(𝑛<sup>2</sup>) ：
```java
/* 平方阶 */
int quadratic(int n) {
    int count = 0;
    // 循环次数与数据大小 n 成平方关系
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            count++;
        }
    }
    return count;
}
```
![[Pasted image 20240524135725.png]]
以冒泡排序为例，外层循环执行 𝑛−1 次，内层循环执行 𝑛−1、𝑛−2、…、2、1 次，平均为 𝑛/2 次，因此时间复杂度为 𝑂((𝑛−1)𝑛/2)=𝑂(𝑛2) ：
```java
/* 平方阶（冒泡排序） */
int bubbleSort(int[] nums) {
    int count = 0; // 计数器
    // 外循环：未排序区间为 [0, i]
    for (int i = nums.length - 1; i > 0; i--) {
        // 内循环：将未排序区间 [0, i] 中的最大元素交换至该区间的最右端
        for (int j = 0; j < i; j++) {
            if (nums[j] > nums[j + 1]) {
                // 交换 nums[j] 与 nums[j + 1]
                int tmp = nums[j];
                nums[j] = nums[j + 1];
                nums[j + 1] = tmp;
                count += 3; // 元素交换包含 3 个单元操作
            }
        }
    }
    return count;
}
```
### 4.   指数阶 𝑂(2<sup>𝑛</sup>)

生物学的“细胞分裂”是指数阶增长的典型例子：初始状态为 1 个细胞，分裂一轮后变为 2 个，分裂两轮后变为 4 个，以此类推，分裂 𝑛 轮后有 2<sup>𝑛</sup> 个细胞。
以下代码模拟了细胞分裂的过程，时间复杂度为 𝑂(2𝑛) ：
```java
/* 指数阶（循环实现） */
int exponential(int n) {
    int count = 0, base = 1;
    // 细胞每轮一分为二，形成数列 1, 2, 4, 8, ..., 2^(n-1)
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < base; j++) {
            count++;
        }
        base *= 2;
    }
    // count = 1 + 2 + 4 + 8 + .. + 2^(n-1) = 2^n - 1
    return count;
}
```
![[Pasted image 20240524140827.png]]
在实际算法中，指数阶常出现于递归函数中。例如在以下代码中，其递归地一分为二，经过 𝑛 次分裂后停止：
```java
/* 指数阶（递归实现） */
int expRecur(int n) {
    if (n == 1)
        return 1;
    return expRecur(n - 1) + expRecur(n - 1) + 1;
}
```
指数阶增长非常迅速，在穷举法（暴力搜索、回溯等）中比较常见。对于数据规模较大的问题，指数阶是不可接受的，通常需要使用动态规划或贪心算法等来解决。
### 5.   对数阶 𝑂(log⁡ 𝑛)

与指数阶相反，对数阶反映了“每轮缩减到一半”的情况。设输入数据大小为 𝑛 ，由于每轮缩减到一半，因此循环次数是 log2⁡𝑛 ，即 2𝑛 的反函数。
以下代码模拟了“每轮缩减到一半”的过程，时间复杂度为 𝑂(log<sub>2⁡</sub>𝑛) ，简记为 𝑂(log⁡𝑛) ：
```java
/* 对数阶（循环实现） */
int logarithmic(int n) {
    int count = 0;
    while (n > 1) {
        n = n / 2;
        count++;
    }
    return count;
}
```
![[Pasted image 20240524144703.png]]
与指数阶类似，对数阶也常出现于递归函数中。以下代码形成了一棵高度为 log2⁡𝑛 的递归树：
```java
/* 对数阶（递归实现） */
int logRecur(int n) {
    if (n <= 1)
        return 0;
    return logRecur(n / 2) + 1;
}
```
对数阶常出现于基于分治策略的算法中，体现了“一分为多”和“化繁为简”的算法思想。它增长缓慢，是仅次于常数阶的理想的时间复杂度。
### 6.   线性对数阶 𝑂(𝑛log⁡𝑛)

线性对数阶常出现于嵌套循环中，两层循环的时间复杂度分别为 𝑂(log⁡𝑛) 和 𝑂(𝑛) 。相关代码如下：
```java
/* 线性对数阶 */
int linearLogRecur(int n) {
    if (n <= 1)
        return 1;
    int count = linearLogRecur(n / 2) + linearLogRecur(n / 2);
    for (int i = 0; i < n; i++) {
        count++;
    }
    return count;
}
```
下图展示了线性对数阶的生成方式。二叉树的每一层的操作总数都为 𝑛 ，树共有 log<sub>2</sub>⁡𝑛+1 层，因此时间复杂度为 𝑂(𝑛log⁡𝑛) 。
![[Pasted image 20240524154726.png]]
主流排序算法的时间复杂度通常为 𝑂(𝑛log⁡𝑛) ，例如快速排序、归并排序、堆排序等。
### 7.   阶乘阶 𝑂(𝑛!)

阶乘阶对应数学上的“全排列”问题。给定 𝑛 个互不重复的元素，求其所有可能的排列方案，方案数量为：

$$
𝑛!=𝑛×(𝑛−1)×(𝑛−2)×⋯×2×1
$$

阶乘通常使用递归实现。如图 2-14 和以下代码所示，第一层分裂出 𝑛 个，第二层分裂出 𝑛−1 个，以此类推，直至第 𝑛 层时停止分裂：
```java
/* 阶乘阶（递归实现） */
int factorialRecur(int n) {
    if (n == 0)
        return 1;
    int count = 0;
    // 从 1 个分裂出 n 个
    for (int i = 0; i < n; i++) {
        count += factorialRecur(n - 1);
    }
    return count;
}
```
![[Pasted image 20240524154914.png]]
请注意，因为当 𝑛≥4 时恒有 𝑛!>2𝑛 ，所以阶乘阶比指数阶增长得更快，在 𝑛 较大时也是不可接受的。
## 最差、最佳、平均时间复杂度 
**算法的时间效率往往不是固定的，而是与输入数据的分布有关**。假设输入一个长度为 𝑛 的数组 `nums` ，其中 `nums` 由从 1 至 𝑛 的数字组成，每个数字只出现一次；但元素顺序是随机打乱的，任务目标是返回元素 1 的索引。我们可以得出以下结论。

- 当 `nums = [?, ?, ..., 1]` ，即当末尾元素是 1 时，需要完整遍历数组，**达到最差时间复杂度 𝑂(𝑛)** 。
- 当 `nums = [1, ?, ?, ...]` ，即当首个元素为 1 时，无论数组多长都不需要继续遍历，**达到最佳时间复杂度 Ω(1)** 。

“最差时间复杂度”对应函数渐近上界，使用大 𝑂 记号表示。相应地，“最佳时间复杂度”对应函数渐近下界，用 Ω 记号表示：
```java
/* 生成一个数组，元素为 { 1, 2, ..., n }，顺序被打乱 */
int[] randomNumbers(int n) {
    Integer[] nums = new Integer[n];
    // 生成数组 nums = { 1, 2, 3, ..., n }
    for (int i = 0; i < n; i++) {
        nums[i] = i + 1;
    }
    // 随机打乱数组元素
    Collections.shuffle(Arrays.asList(nums));
    // Integer[] -> int[]
    int[] res = new int[n];
    for (int i = 0; i < n; i++) {
        res[i] = nums[i];
    }
    return res;
}

/* 查找数组 nums 中数字 1 所在索引 */
int findOne(int[] nums) {
    for (int i = 0; i < nums.length; i++) {
        // 当元素 1 在数组头部时，达到最佳时间复杂度 O(1)
        // 当元素 1 在数组尾部时，达到最差时间复杂度 O(n)
        if (nums[i] == 1)
            return i;
    }
    return -1;
}
```
值得说明的是，我们在实际中很少使用最佳时间复杂度，因为通常只有在很小概率下才能达到，可能会带来一定的误导性。**而最差时间复杂度更为实用，因为它给出了一个效率安全值**，让我们可以放心地使用算法。

从上述示例可以看出，最差时间复杂度和最佳时间复杂度只出现于“特殊的数据分布”，这些情况的出现概率可能很小，并不能真实地反映算法运行效率。相比之下，**平均时间复杂度可以体现算法在随机输入数据下的运行效率**，用 Θ 记号来表示。

对于部分算法，我们可以简单地推算出随机数据分布下的平均情况。比如上述示例，由于输入数组是被打乱的，因此元素 1 出现在任意索引的概率都是相等的，那么算法的平均循环次数就是数组长度的一半 𝑛/2 ，平均时间复杂度为 Θ(𝑛/2)=Θ(𝑛) 。

但对于较为复杂的算法，计算平均时间复杂度往往比较困难，因为很难分析出在数据分布下的整体数学期望。在这种情况下，我们通常使用最差时间复杂度作为算法效率的评判标准。